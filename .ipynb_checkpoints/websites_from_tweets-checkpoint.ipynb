{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we're only looking at the first set of tweets.\n",
    "# Get Data from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = open('all_tweets/IRAhandle_tweets_1.csv') # change this to whatever group you wanna look at\n",
    "data = list(csv.DictReader(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243891\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the domains that these tweets are linking to.\n",
    "# Get Domain Info & Sort Into All / Russian / Non-Russian\n",
    "##### Format of each dictionary:\n",
    "\n",
    "{(string) *domain_name*: (array) [(int) *count*, (array) *tweet_id's* linking to this domain]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_categories = ['tco1_step1', 'tco2_step1', 'tco3_step1']\n",
    "user_info = ['author']\n",
    "details = ['retweet', 'account_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com\n"
     ]
    }
   ],
   "source": [
    "domain_starters = ['http://', 'https://']\n",
    "common_bits = ['www.', '.com']\n",
    "\n",
    "unique_domains = {}\n",
    "russian_sites = {}\n",
    "non_russian_sites = {}\n",
    "\n",
    "COUNT_IND = 0\n",
    "TWT_ID_IND = 1\n",
    "\n",
    "def get_domain_old(link, no_common = False):\n",
    "    # removes the http:// and https://, and does not have the ending slash\n",
    "    longest_starter_len = max([len(i) for i in domain_starters])\n",
    "    longest_common_len = max([len(i) for i in common_bits])\n",
    "    for ds in domain_starters:\n",
    "        if ds in link[:longest_starter_len]:\n",
    "            beginning = link[len(ds):].split('/')[0]\n",
    "            if no_common:\n",
    "                for b in common_bits:\n",
    "                    if b in beginning:\n",
    "                        beginning = [r for r in beginning.split(b) if r != ''][0] \n",
    "            return beginning.lower()\n",
    "\n",
    "def get_domain(link, no_common = False):\n",
    "    longest_common_len = max([len(i) for i in common_bits])\n",
    "    beginning = '/'.join(link.split('/')[:3]) # we assume we have something like pre://domain_name/...\n",
    "    if no_common:\n",
    "        for b in common_bits:\n",
    "            if b in beginning:\n",
    "                beginning = [r for r in beginning.split(b) if r != ''][0] \n",
    "    return beginning.lower() + '/'\n",
    "        \n",
    "def basic_dict_checks(dct, key, twt_id):\n",
    "    if key in dct.keys():\n",
    "        dct[key][COUNT_IND] += 1\n",
    "        dct[key][TWT_ID_IND] += [twt_id]\n",
    "    else:\n",
    "        dct[key] = []\n",
    "        dct[key] += [1]\n",
    "        dct[key] += [[twt_id]]\n",
    "print(get_domain(\"https://www.youtube.com/hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in data:\n",
    "    tweet_id = tweet['tweet_id']\n",
    "    for link in link_categories:\n",
    "        dom = get_domain(tweet[link])\n",
    "        if dom:\n",
    "            basic_dict_checks(unique_domains, dom, tweet_id)\n",
    "            if '.ru' in dom:\n",
    "                basic_dict_checks(russian_sites, dom, tweet_id)\n",
    "            else:\n",
    "                basic_dict_checks(non_russian_sites, dom, tweet_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the Domains (now stored in lists) by Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_domains = sorted(unique_domains.items(), key=lambda k: k[1][0], reverse=True)\n",
    "sorted_russian_sites = sorted(russian_sites.items(), key=lambda k: k[1][0], reverse=True)\n",
    "sorted_non_russian_sites = sorted(non_russian_sites.items(), key=lambda k: k[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def domain_basics(site_info):\n",
    "    # returns an array with the domain name and number of tweets linking to that domain\n",
    "    return [site_info[0], site_info[1][COUNT_IND]]\n",
    "def print_title(title):\n",
    "    print(title)\n",
    "    print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Referenced Sites in Russian Tweets (Ignoring Twitter)\n",
      "========================================\n",
      "['ift.tt', 24008]\n",
      "\n",
      "RUSSIAN: ['www.gazeta.ru', 7738]\n",
      "\n",
      "['bit.ly', 7592]\n",
      "\n",
      "RUSSIAN: ['ria.ru', 3945]\n",
      "\n",
      "['dlvr.it', 3794]\n",
      "['twibble.io', 3427]\n",
      "['twib.in', 3122]\n",
      "\n",
      "RUSSIAN: ['tass.ru', 2921]\n",
      "\n",
      "['www.fox5atlanta.com', 2706]\n",
      "['ow.ly', 2349]\n",
      "['usfreedomarmy.com', 2070]\n",
      "['youtu.be', 1871]\n",
      "['www.youtube.com', 1828]\n",
      "['fb.me', 1668]\n",
      "['goo.gl', 1633]\n",
      "['www.kob.com', 1615]\n",
      "['www.instagram.com', 1221]\n",
      "['russian.rt.com', 1167]\n",
      "['krqe.com', 1152]\n",
      "\n",
      "RUSSIAN: ['www.rbc.ru', 1128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Top 20 Referenced Sites in Russian Tweets (Ignoring Twitter)\")\n",
    "for site in sorted_domains[1:21]:\n",
    "    if '.ru' in site[0]:\n",
    "        print('\\nRUSSIAN: ' + str(domain_basics(site)) + '\\n')\n",
    "    else:\n",
    "        print(domain_basics(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Russian Sites in Russian Tweets\n",
      "========================================\n",
      "['www.gazeta.ru', 7738]\n",
      "['ria.ru', 3945]\n",
      "['tass.ru', 2921]\n",
      "['www.rbc.ru', 1128]\n",
      "['www.postsovet.ru', 942]\n",
      "['riafan.ru', 575]\n",
      "['r.rbc.ru', 486]\n",
      "['tvrain.ru', 427]\n",
      "['rsport.ru', 413]\n",
      "['vesti.ru', 323]\n",
      "['www.vesti.ru', 310]\n",
      "['lifenews.ru', 291]\n",
      "['www.kp.ru', 268]\n",
      "['izvestia.ru', 244]\n",
      "['top.rbc.ru', 210]\n",
      "['vz.ru', 203]\n",
      "['tvzvezda.ru', 200]\n",
      "['go.tass.ru', 194]\n",
      "['www.ntv.ru', 148]\n",
      "['echo.msk.ru', 114]\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Top 20 Russian Sites in Russian Tweets\")\n",
    "for site in sorted_russian_sites[:20]:\n",
    "    print(domain_basics(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Non-Russian Sites in Russian Tweets\n",
      "========================================\n",
      "['twitter.com', 121457]\n",
      "['ift.tt', 24008]\n",
      "['bit.ly', 7592]\n",
      "['dlvr.it', 3794]\n",
      "['twibble.io', 3427]\n",
      "['twib.in', 3122]\n",
      "['www.fox5atlanta.com', 2706]\n",
      "['ow.ly', 2349]\n",
      "['usfreedomarmy.com', 2070]\n",
      "['youtu.be', 1871]\n",
      "['www.youtube.com', 1828]\n",
      "['fb.me', 1668]\n",
      "['goo.gl', 1633]\n",
      "['www.kob.com', 1615]\n",
      "['www.instagram.com', 1221]\n",
      "['russian.rt.com', 1167]\n",
      "['krqe.com', 1152]\n",
      "['dld.bz', 965]\n",
      "['ind.pn', 904]\n",
      "['larep.it', 843]\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Top 20 Non-Russian Sites in Russian Tweets\")\n",
    "for site in sorted_non_russian_sites[:20]:\n",
    "    print(domain_basics(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers for Sites\n",
      "========================================\n",
      "Russian: 436\n",
      "Non-Russian: 5508\n",
      "Total of 5944 unique domains for 243891 tweets\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Numbers for Sites\")\n",
    "print('Russian: ' + str(len(sorted_russian_sites)))\n",
    "print('Non-Russian: ' + str(len(sorted_non_russian_sites)))\n",
    "print('Total of ' + str(len(sorted_domains)) + ' unique domains for ' + str(len(data)) + ' tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Preliminary Observations:\n",
    "### Some automation websites\n",
    "dlvr.it, twibble.io + twib.in\n",
    "### A lot of shortening websites\n",
    "tinyurl, bit.ly, ow.ly, goo.gl, fb.me\n",
    "### A few repeated websites w/ 'different' domains\n",
    "youtu.be vs youtube.com, rbc.com\n",
    "### Top sites are:\n",
    "shortening websites, automation websites, social media, Fox news, USFreedomArmy\n",
    "# NEXT question: matching with our categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = open('all_tweets/IRAhandle_tweets_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
