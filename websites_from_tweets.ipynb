{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we're only looking at the first set of tweets.\n",
    "# Get Data from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = open('all_tweets/IRAhandle_tweets_1.csv') # change this to whatever group you wanna look at\n",
    "data = list(csv.DictReader(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243891\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the domains that these tweets are linking to.\n",
    "# Get Domain Info & Sort Into All / Russian / Non-Russian\n",
    "##### Format of each dictionary:\n",
    "\n",
    "{(string) *domain_name*: (array) [(int) *count*, (array) *tweet_id's* linking to this domain]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_categories = ['tco1_step1', 'tco2_step1', 'tco3_step1']\n",
    "user_info = ['author']\n",
    "details = ['retweet', 'account_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.youtu.be/\n"
     ]
    }
   ],
   "source": [
    "domain_starters = ['http://', 'https://']\n",
    "common_bits = ['www.', '.com']\n",
    "\n",
    "def get_domain_old(link, no_common = False):\n",
    "    # removes the http:// and https://, and does not have the ending slash\n",
    "    longest_starter_len = max([len(i) for i in domain_starters])\n",
    "    longest_common_len = max([len(i) for i in common_bits])\n",
    "    for ds in domain_starters:\n",
    "        if ds in link[:longest_starter_len]:\n",
    "            beginning = link[len(ds):].split('/')[0]\n",
    "            if no_common:\n",
    "                for b in common_bits:\n",
    "                    if b in beginning:\n",
    "                        beginning = [r for r in beginning.split(b) if r != ''][0] \n",
    "            return beginning.lower()\n",
    "\n",
    "def get_domain(link, no_common = False):\n",
    "    longest_common_len = max([len(i) for i in common_bits])\n",
    "    beginning = '/'.join(link.split('/')[:3]) # we assume we have something like pre://domain_name/...\n",
    "    if no_common:\n",
    "        for b in common_bits:\n",
    "            if b in beginning:\n",
    "                beginning = [r for r in beginning.split(b) if r != ''][0]\n",
    "    return beginning.lower() + '/'\n",
    "        \n",
    "def basic_dict_checks(dct, key, twt_id):\n",
    "    if key in dct.keys():\n",
    "        dct[key][COUNT_IND] += 1\n",
    "        dct[key][TWT_ID_IND] += [twt_id]\n",
    "    else:\n",
    "        dct[key] = []\n",
    "        dct[key] += [1]\n",
    "        dct[key] += [[twt_id]]\n",
    "print(get_domain(\"http://www.youtu.be/hiwww\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_domains = {}\n",
    "russian_sites = {}\n",
    "non_russian_sites = {}\n",
    "\n",
    "COUNT_IND = 0\n",
    "TWT_ID_IND = 1\n",
    "\n",
    "total_links = 0\n",
    "\n",
    "for tweet in data:\n",
    "    tweet_id = tweet['tweet_id']\n",
    "    for link in link_categories:\n",
    "        dom = get_domain(tweet[link])\n",
    "        if dom and dom != '/':\n",
    "            basic_dict_checks(unique_domains, dom, tweet_id)\n",
    "            if '.ru' in dom:\n",
    "                basic_dict_checks(russian_sites, dom, tweet_id)\n",
    "            else:\n",
    "                basic_dict_checks(non_russian_sites, dom, tweet_id)\n",
    "            total_links += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the Domains (now stored in lists) by Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_domains = sorted(unique_domains.items(), key=lambda k: k[1][0], reverse=True)\n",
    "sorted_russian_sites = sorted(russian_sites.items(), key=lambda k: k[1][0], reverse=True)\n",
    "sorted_non_russian_sites = sorted(non_russian_sites.items(), key=lambda k: k[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def domain_basics(site_info):\n",
    "    # given a site: info pair, returns an array with the domain name and number of tweets linking to that domain\n",
    "    return [site_info[0], site_info[1][COUNT_IND]]\n",
    "def print_title(title):\n",
    "    print(title)\n",
    "    print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Referenced Sites in Russian Tweets (Ignoring Twitter)\n",
      "========================================\n",
      "['http://ift.tt/', 24008]\n",
      "\n",
      "RUSSIAN: ['http://www.gazeta.ru/', 7728]\n",
      "\n",
      "['http://bit.ly/', 7552]\n",
      "['http://dlvr.it/', 3794]\n",
      "\n",
      "RUSSIAN: ['http://ria.ru/', 3548]\n",
      "\n",
      "['https://twibble.io/', 3427]\n",
      "['http://twib.in/', 3122]\n",
      "\n",
      "RUSSIAN: ['http://tass.ru/', 2921]\n",
      "\n",
      "['http://www.fox5atlanta.com/', 2706]\n",
      "['http://ow.ly/', 2349]\n",
      "['http://usfreedomarmy.com/', 2070]\n",
      "['http://fb.me/', 1668]\n",
      "['http://www.kob.com/', 1615]\n",
      "['https://www.youtube.com/', 1494]\n",
      "['https://youtu.be/', 1258]\n",
      "['https://goo.gl/', 1256]\n",
      "['https://www.instagram.com/', 1220]\n",
      "['http://krqe.com/', 1152]\n",
      "\n",
      "RUSSIAN: ['http://www.rbc.ru/', 1128]\n",
      "\n",
      "['http://dld.bz/', 965]\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Top 20 Referenced Sites in Russian Tweets (Ignoring Twitter)\")\n",
    "for site in sorted_domains[1:21]:\n",
    "    if '.ru' in site[0]:\n",
    "        print('\\nRUSSIAN: ' + str(domain_basics(site)) + '\\n')\n",
    "    else:\n",
    "        print(domain_basics(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Russian Sites in Russian Tweets\n",
      "========================================\n",
      "['http://www.gazeta.ru/', 7728]\n",
      "['http://ria.ru/', 3548]\n",
      "['http://tass.ru/', 2921]\n",
      "['http://www.rbc.ru/', 1128]\n",
      "['http://www.postsovet.ru/', 942]\n",
      "['http://riafan.ru/', 561]\n",
      "['http://r.rbc.ru/', 486]\n",
      "['http://rsport.ru/', 413]\n",
      "['https://ria.ru/', 397]\n",
      "['http://vesti.ru/', 323]\n",
      "['http://www.vesti.ru/', 310]\n",
      "['http://lifenews.ru/', 291]\n",
      "['https://tvrain.ru/', 286]\n",
      "['http://www.kp.ru/', 268]\n",
      "['http://izvestia.ru/', 244]\n",
      "['http://top.rbc.ru/', 210]\n",
      "['http://vz.ru/', 201]\n",
      "['http://tvzvezda.ru/', 200]\n",
      "['http://go.tass.ru/', 194]\n",
      "['http://www.ntv.ru/', 148]\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Top 20 Russian Sites in Russian Tweets\")\n",
    "for site in sorted_russian_sites[:20]:\n",
    "    print(domain_basics(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Non-Russian Sites in Russian Tweets\n",
      "========================================\n",
      "['https://twitter.com/', 121457]\n",
      "['http://ift.tt/', 24008]\n",
      "['http://bit.ly/', 7552]\n",
      "['http://dlvr.it/', 3794]\n",
      "['https://twibble.io/', 3427]\n",
      "['http://twib.in/', 3122]\n",
      "['http://www.fox5atlanta.com/', 2706]\n",
      "['http://ow.ly/', 2349]\n",
      "['http://usfreedomarmy.com/', 2070]\n",
      "['http://fb.me/', 1668]\n",
      "['http://www.kob.com/', 1615]\n",
      "['https://www.youtube.com/', 1494]\n",
      "['https://youtu.be/', 1258]\n",
      "['https://goo.gl/', 1256]\n",
      "['https://www.instagram.com/', 1220]\n",
      "['http://krqe.com/', 1152]\n",
      "['http://dld.bz/', 965]\n",
      "['https://russian.rt.com/', 943]\n",
      "['http://ind.pn/', 904]\n",
      "['http://larep.it/', 843]\n"
     ]
    }
   ],
   "source": [
    "print_title(\"Top 20 Non-Russian Sites in Russian Tweets\")\n",
    "for site in sorted_non_russian_sites[:20]:\n",
    "    print(domain_basics(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of Unique Domains:\n",
      "========================================\n",
      "Russian: 479\n",
      "Non-Russian: 5756\n",
      "for a total of 6235 unique domains for 243891 tweets\n",
      "percentage of unique Russian sites over all: 7.68%\n",
      "\n",
      "Number of Links to Domains:\n",
      "========================================\n",
      "Russian: 23240\n",
      "Non-Russian: 226515\n",
      "for a total of 249755 links in 243891 tweets\n",
      "percentage of Russian links over all: 9.31%\n"
     ]
    }
   ],
   "source": [
    "t_russites = len(sorted_russian_sites)\n",
    "t_norussites = len(sorted_non_russian_sites)\n",
    "t_sites = len(sorted_domains)\n",
    "total_tweets = len(data)\n",
    "\n",
    "t_ruslinks = sum([deet[0] for (name, deet) in sorted_russian_sites])\n",
    "t_noruslinks = sum([deet[0] for (name, deet) in sorted_non_russian_sites])\n",
    "\n",
    "print_title(\"Numbers of Unique Domains:\")\n",
    "print('Russian: ' + str(t_russites))\n",
    "print('Non-Russian: ' + str(t_norussites))\n",
    "print('for a total of ' + str(t_sites) + ' unique domains for ' + str(total_tweets) + ' tweets')\n",
    "print('percentage of unique Russian sites over all: ' + str(round(t_russites / t_sites * 100, 2)) + '%')\n",
    "\n",
    "print_title(\"\\nNumber of Links to Domains:\")\n",
    "print('Russian: ' + str(t_ruslinks))\n",
    "print('Non-Russian: ' + str(t_noruslinks))\n",
    "print('for a total of ' + str(total_links) + ' links in ' + str(total_tweets) + ' tweets')\n",
    "print('percentage of Russian links over all: ' + str(round(t_ruslinks / total_links * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Preliminary Observations:\n",
    "### Some automation websites\n",
    "dlvr.it, twibble.io + twib.in, ift.tt (?)\n",
    "### A lot of shortening websites\n",
    "tinyurl, bit.ly, ow.ly, goo.gl, fb.me\n",
    "### A few repeated websites w/ 'different' domains\n",
    "youtu.be vs youtube.com, rbc.com\n",
    "### Top sites are:\n",
    "shortening websites, automation websites, social media, Fox news, USFreedomArmy; RUSSIATODAY (not included in Russian websites right now)\n",
    "# NEXT question: matching with our categories?\n",
    "## NOTE: this is all without having figured out all shortlink websites thus far; numbers may (?) go up afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_and_match_sites(types):\n",
    "    # takes a list of category names\n",
    "    sites = []\n",
    "    for name in types:\n",
    "        sites += [i.rstrip('\\n') for i in open('categories/' + name).readlines()]\n",
    "    matching = []\n",
    "    for site in sites:\n",
    "        if site in unique_domains.keys():\n",
    "            matching += [(site, unique_domains[site][0])]\n",
    "    return matching\n",
    "\n",
    "def total_matches(matches):\n",
    "    return sum([num for name, num in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_matches = read_and_match_sites(['fake-news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Matching Fake News Sites & Counts\n",
      "========================================\n",
      "('http://www.thegatewaypundit.com/', 307)\n",
      "('http://conservativetribune.com/', 122)\n",
      "('http://bb4sp.com/', 58)\n",
      "('http://www.dcclothesline.com/', 49)\n",
      "('http://beforeitsnews.com/', 43)\n",
      "('http://eaglerising.com/', 43)\n",
      "('http://100percentfedup.com/', 31)\n",
      "('https://www.jihadwatch.org/', 27)\n",
      "('http://www.truthrevolt.org/', 22)\n",
      "('https://conservativedailypost.com/', 20)\n",
      "('http://conservativefighters.com/', 20)\n",
      "('http://pamelageller.com/', 19)\n",
      "('http://rickwells.us/', 15)\n",
      "('http://www.frontpagemag.com/', 15)\n",
      "('http://freedomdaily.com/', 13)\n",
      "('http://endingthefed.com/', 11)\n",
      "('http://www.israelvideonetwork.com/', 11)\n",
      "('http://www.barenakedislam.com/', 10)\n",
      "('http://freedomoutpost.com/', 10)\n",
      "('http://allenwestrepublic.com/', 8)\n",
      "\n",
      "Total Fake link matches: 1034 out of 249755 total links\n",
      "Percentage fake over all: 0.414 %\n"
     ]
    }
   ],
   "source": [
    "print_title('Top 20 Matching Fake News Sites & Counts')\n",
    "for i in sorted(fake_matches, key = operator.itemgetter(1), reverse=True)[:20]:\n",
    "    print(i)\n",
    "print('\\nTotal Fake link matches: ' + str(total_matches(fake_matches)) + ' out of ' + str(total_links) + ' total links')\n",
    "print('Percentage fake over all: ' + str(round(total_matches(fake_matches) / total_links * 100, 3)) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conspiracy_matches = read_and_match_sites(['conspiracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Matching Conspiracy Sites & Counts\n",
      "========================================\n",
      "('http://www.zerohedge.com/', 212)\n",
      "('http://www.infowars.com/', 116)\n",
      "('http://truepundit.com/', 71)\n",
      "('http://worldtruth.tv/', 29)\n",
      "('http://consciouslifenews.com/', 21)\n",
      "('http://www.disclose.tv/', 21)\n",
      "('http://yournewswire.com/', 20)\n",
      "('http://21stcenturywire.com/', 18)\n",
      "('http://countercurrentnews.com/', 17)\n",
      "('http://www.veteranstoday.com/', 14)\n",
      "('http://shoebat.com/', 12)\n",
      "('http://www.activistpost.com/', 11)\n",
      "('http://www.nowtheendbegins.com/', 10)\n",
      "('http://www.ecowatch.com/', 7)\n",
      "('http://www.globalresearch.ca/', 7)\n",
      "('http://wearechange.org/', 7)\n",
      "('http://theantimedia.org/', 7)\n",
      "('http://www.coasttocoastam.com/', 6)\n",
      "('https://www.sott.net/', 6)\n",
      "('http://www.centerforsecuritypolicy.org/', 5)\n",
      "\n",
      "Total Conspiracy link matches: 675 out of 249755 total_links\n",
      "Percentage conspiracy over all: 0.27 %\n"
     ]
    }
   ],
   "source": [
    "print_title('Top 20 Matching Conspiracy Sites & Counts')\n",
    "for i in sorted(conspiracy_matches, key = operator.itemgetter(1), reverse=True)[:20]:\n",
    "    print(i)\n",
    "print('\\nTotal Conspiracy link matches: ' + str(total_matches(conspiracy_matches)) + ' out of ' + str(total_links) + ' total_links')\n",
    "print('Percentage conspiracy over all: ' + str(round(total_matches(conspiracy_matches) / total_links * 100, 3)) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
